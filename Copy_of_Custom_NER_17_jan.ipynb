{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ueA1C7HUNiPpF9ytQJeD0xt2yS7QgOW-",
      "authorship_tag": "ABX9TyMRRlWbfFAiFVq9mJ8ZZexe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsk-003/Air-Quality/blob/main/Copy_of_Custom_NER_17_jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy-transformers"
      ],
      "metadata": {
        "id": "PG-D8LHt0yAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUm15BGLVa5X",
        "outputId": "e6d18cda-f5c0-4b66-ce8e-332fc3efba06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "import spacy\n"
      ],
      "metadata": {
        "id": "jwCv33pB0z_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spacy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2nARJP8s1ATq",
        "outputId": "658762e8-a7e5-4a56-d846-8ffc3a1d1922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.7.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8uuCDzx1W2z",
        "outputId": "409cbb08-ceb9-4248-8726-2e3b79525ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 18 08:59:11 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaMeM9QYz5lQ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "cv_data=json.load(open('/content/drive/MyDrive/cv_data/output/training_data.json','r'))"
      ],
      "metadata": {
        "id": "HTP_xoI00Cy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77Qe6kid0PYv",
        "outputId": "bfad1e39-fa8b-4bf7-fc6e-71a9b98301eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SYSTEMS ENGINEER NEHA RANI Phone: +91-8340674163 Email:nehdstar@gmail.com LinkedIn:https://www.linkedin.com/in/neha-rani- a9839b110/ Location: Pune, MAHARASHTRA-411057 Objective 2 years experienced skilled Engineer with proven success in building successful algorithms & predictive models . Highly adept at clustering & classification(ML), Natural Language Processing, computer vision and Deep Learning to increase business efficiency. Technical Skills Tools: Microsoft Azure, Labellmg Technology: Machine learning, Natural language processing, DEEP Learning, Computer vision and Neural Networks.Languages: Python Work Experience SYSTEMS ENGINEER INFOSYS LIMITED, PUNE  March 2019 PRESENT Project : Sentiment Analysis Project Description : Analysis and Classification of sentiment of customers experience in text form. It involved identification, extraction and scoring of consumer feelings and opinions as it appears in social media, customer surveys, emails, blogs etc. it predicted whether the content of a piece of text data is positive, negative or neutral. It helped in improving customer experience and creating better, more personalized products. Skills: Python, Machine Learning, Natural Language Processing, Deep Learning, Neural Networks. Algorithm: LSTM Technique: Word Embedding Activation Function: RELU, SOFTMAX Virtual Machine: Microsoft Azure Framework: KERAS Project : Object Detection Project Description : object detection model to detect number plate, RF Tags, Barcodes for toll Automation. It gives very high accuracy even in challenging conditions with different fonts, dirty number plates, difficult camera angles. Skills: Python, Machine learning, Deep Learning, Computer vision.Model: Yolo v5 Virtual Machine: Microsoft Azure Technique: Bounding Box Prediction, Object Classification Visualization Tool: Tensorboard Annotation: LabelImg ROLE AND RESPONSIBLITES  Understood business objectives and developed deep learning models that helped to achieve those  objectives, along with metrics to track with their progress. Researched, developed, trained, tested and evaluated deep learning algorithms & models onMicrosoft Azure(Virtual Machine). Analyzed, Selected and implemented right ML Algorithms in order to solve a given problem. Applied appropriate ML techniques, libraries and framework. Extended existing ML Libraries and framework .Verified data quality, and/or ensuring it via data cleaning. Explored and visualized the data to gain an understanding of it. Defined validation strategies.Defined the preprocessing to be done on a given dataset.Defined dataset augmentation pipelines.Generated word embedding by converting word into a word embedding by using a pretrained word embedding model known as GloVe for sentiment Analysis.Annotated the video dataset frame by frame using open source tool LabelImg in yolo format. Defined the Deep learning/AI Model Architecture.Trained the Deep Learning/AI Model and tunned their hyperparameters.Evaluated the trained models performance to improve the accuracy and quality. Tested the Deep Learning/AI model by making inference on test datasets and other unseen dataset as well.Analyzed the errors of the Deep Learning/AI model and designed strategies to overcome them. Knowledge of Adding Deep learning/AI Model to production. Proficiency with deep learning framework such as tensorflow and keras. Proficiency with Python and basic libraries for machine learning such as scikit-learn and pandas. Proficiency with OpenCv and Pytorch.Proficiency with Deep learning algorithms and models such as CNN, RNN and Lstm. Good understanding of linear algebra, machine learning, statistics and machine learning principle(i.e. training, validation,etc).Good understanding of Word2vec,word embedding, bagofwords, information extraction,text mining, stemming, Lemmetization and NER. CERTIFICATIONS Tensorflow for AI-vision basics Coursera | 12/20  12/20 EDUCATION Information technology/ B.TECH KIIT University,BHUBANESHWAR 04/14 04/18 CGPA-7.15 .',\n",
              " {'entities': [[28, 34, 'Name of candidate'],\n",
              "   [193, 200, 'Total Years of Experiance'],\n",
              "   [1219, 1235, 'Skills'],\n",
              "   [3203, 3223, 'Skills'],\n",
              "   [2218, 2249, 'Skills']]}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(cv_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1yMrey90qcb",
        "outputId": "b7e9e3fb-5e19-4932-fa4c-3b2348c07555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(cv_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXIcrpeoLuI7",
        "outputId": "fbe433fc-e1f5-476e-da56-0ea27e1f190e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy-transformers\n",
        "\n",
        "import spacy_transformers"
      ],
      "metadata": {
        "id": "gHRdW3gk1dtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, RobertaModel\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "id": "ba44RF835zDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config /content/drive/MyDrive/cv_data/output/config.cfg config.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO0ZM7agWhAH",
        "outputId": "f8b9d3e8-0e22-469b-a5dd-5083622aa671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-18 06:10:03.167976: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-18 06:10:03.168030: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-18 06:10:03.169626: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-18 06:10:04.676993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spacy_doc(file,data):\n",
        "  nlp = spacy.blank('en')\n",
        "  db = DocBin()\n",
        "\n",
        "  for text,annot in tqdm(data):\n",
        "    doc = nlp.make_doc(text)\n",
        "    annot = annot['entities']\n",
        "\n",
        "    ents = []\n",
        "    entity_indices = []\n",
        "\n",
        "    for start, end, label in annot:\n",
        "      skip_entity = False\n",
        "      for idx in range(start, end):\n",
        "        if idx in entity_indices:\n",
        "          skip_entity = True\n",
        "          break\n",
        "      if skip_entity==True:\n",
        "        continue\n",
        "\n",
        "      entity_indices = entity_indices + list(range(start, end))\n",
        "\n",
        "      try:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
        "\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      if span is None:\n",
        "        err_data = str([start, end]) + \"     \" + str(text)  + \"\\n\"\n",
        "        file.write(err_data)\n",
        "\n",
        "      else:\n",
        "        ents.append(span)\n",
        "\n",
        "    try:\n",
        "      doc.ents = ents\n",
        "      db.add(doc)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  return db"
      ],
      "metadata": {
        "id": "gzOvVxaPKbdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "train,test = train_test_split(cv_data, test_size=0.2)"
      ],
      "metadata": {
        "id": "BiYp1NG8Kbra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train),len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvJEPqTjKcxr",
        "outputId": "b8b3e788-69de-455f-f719-f2fb62f90dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('error.txt','w')\n",
        "\n",
        "db = get_spacy_doc(file,train)\n",
        "db.to_disk('train_data.spacy')\n",
        "\n",
        "\n",
        "db = get_spacy_doc(file,test)\n",
        "db.to_disk('test_data.spacy')\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d93ziKmpMcuh",
        "outputId": "571d46dd-b5a3-4c90-9116-474acb21cf46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 12.44it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 11.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python -m spacy debug config config.cfg\n",
        "!python -m spacy train /content/config.cfg --output ./output --paths.train ./train_data.spacy --paths.dev ./test_data.spacy --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJZRXIwEY24r",
        "outputId": "22535909-aa1f-4a81-b007-7a32b6e50f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-18 06:12:10.372273: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-18 06:12:10.372337: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-18 06:12:10.373691: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-18 06:12:11.421394: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0         788.96   1736.01    0.00    0.00    0.00    0.00\n",
            " 50     200       53101.16  57318.63    0.00    0.00    0.00    0.00\n",
            "100     400        4408.78   6341.15    0.00    0.00    0.00    0.00\n",
            "150     600           0.00   6353.89    0.00    0.00    0.00    0.00\n",
            "200     800           0.00   6312.92    0.00    0.00    0.00    0.00\n",
            "250    1000           0.00   6302.51    0.00    0.00    0.00    0.00\n",
            "300    1200           0.00   6285.56    0.00    0.00    0.00    0.00\n",
            "350    1400           0.00   6264.74    0.00    0.00    0.00    0.00\n",
            "400    1600           0.00   6257.28    0.00    0.00    0.00    0.00\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yiJGiYYL59OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "twM1VUkvkWFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('/content/output/model-best')"
      ],
      "metadata": {
        "id": "TYBUBMusXRfQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "229a5230-357f-46e6-b07e-0435c0ab7ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'spacy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-650d8a6cb494>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/output/model-best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp('Aniruddha Kawarase anujabagad18@gmail.com +91-8421675729 Profile Summary  2 year Experience Machine Learning Engineer with over 2 years of experience in IT Industry.')\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \"->>>>\",ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tFUUXVeXRib",
        "outputId": "6f568164-40f7-4282-8fcb-ba7187bc27cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aniruddha Kawarase ->>>> Name of candidate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsqI9QEvPTsF",
        "outputId": "ba8b1bee-31b9-48d6-932b-c08959336980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.23.15)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.9 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.23.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, fitz"
      ],
      "metadata": {
        "id": "sNIvr47qYW6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = '/content/drive/MyDrive/cv_data/Neha.pdf'"
      ],
      "metadata": {
        "id": "S1BsHznQYbcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = fitz.open(fname)\n",
        "doc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T9CJL3UYjH7",
        "outputId": "862d1c17-a0e1-4179-dd06-3d52087af74a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document('/content/drive/MyDrive/cv_data/Neha.pdf')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \"\n",
        "for page in doc:\n",
        "  text = text + str(page.get_text())"
      ],
      "metadata": {
        "id": "aFEzpwkCZGAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "bJTgbK5_ZzCf",
        "outputId": "3ef5ef73-3dac-41f9-cf0d-b5b04fbcf747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' SYSTEMS ENGINEER \\nNEHA RANI \\nPhone: +91-8340674163 \\nEmail:nehdstar@gmail.com \\nLinkedIn:https://www.linke \\ndin.com/in/neha-rani- \\na9839b110/ \\nLocation: Pune, \\nMAHARASHTRA-411057 \\n \\n \\nObjective \\n2 years experienced skilled Engineer with proven success in building successful algorithms & \\npredictive models . Highly adept at clustering & classification(ML), Natural Language \\nProcessing, computer vision and Deep Learning to increase business efficiency. \\nTechnical Skills \\n \\nTools: Microsoft Azure, Labellmg \\nTechnology: Machine learning, Natural language processing, DEEP \\nLearning, Computer vision and Neural Networks. \\nLanguages: Python \\n \\nWork Experience \\n \\nSYSTEMS ENGINEER \\nINFOSYS LIMITED, PUNE • March 2019 – PRESENT \\n \\n• Project : Sentiment Analysis \\nProject Description : Analysis and Classification of sentiment of \\ncustomers experience in text form. It involved identification, \\nextraction and scoring of consumer feelings and opinions as it \\nappears in social media, customer surveys, emails, blogs etc. it \\npredicted whether the content of a piece of text data is positive, \\nnegative or neutral. It helped in improving customer experience and \\ncreating better, more personalized products. \\nSkills: Python, Machine Learning, Natural Language Processing, Deep Learning, \\nNeural Networks. \\nAlgorithm: LSTM \\nTechnique: Word Embedding \\nActivation Function: RELU, SOFTMAX \\nVirtual Machine: Microsoft Azure \\nFramework: KERAS \\n• Project : Object Detection \\nProject Description : object detection model to detect number plate, \\nRF Tags, Barcodes for toll Automation. It gives very high accuracy \\neven in challenging conditions with different fonts, dirty number \\nplates, difficult camera angles. \\nSkills: Python, Machine learning, Deep Learning, Computer vision. \\nModel: Yolo v5 \\nVirtual Machine: Microsoft Azure \\nTechnique: Bounding Box Prediction, Object Classification \\nVisualization Tool: Tensorboard \\nAnnotation: LabelImg \\n \\nROLE AND RESPONSIBLITES \\n \\n \\n• \\nUnderstood business objectives and developed deep learning models that helped to achieve those \\nobjectives, along with metrics to track with their progress. \\n• \\nResearched, developed, trained, tested and evaluated deep learning algorithms & models on \\nMicrosoft Azure(Virtual Machine). \\n• \\nAnalyzed, Selected and implemented right ML Algorithms in order to solve a given problem. \\n• \\nApplied appropriate ML techniques, libraries and framework. \\n• \\nExtended existing ML Libraries and framework . \\n• \\nVerified data quality, and/or ensuring it via data cleaning. \\n• \\nExplored and visualized the data to gain an understanding of it. \\n• \\nDefined validation strategies. \\n• \\nDefined the preprocessing to be done on a given dataset. \\n• \\nDefined dataset augmentation pipelines. \\n• \\nGenerated word embedding by converting word into a word embedding by using a pretrained \\nword embedding model known as GloVe for sentiment Analysis. \\n• \\nAnnotated the video dataset frame by frame using open source tool LabelImg in yolo format. \\n• \\nDefined the Deep learning/AI Model Architecture. \\n• \\nTrained the Deep Learning/AI Model and tunned their hyperparameters. \\n• \\nEvaluated the trained model’s performance to improve the accuracy and quality. \\n• \\nTested the Deep Learning/AI model by making inference on test datasets and other unseen \\ndataset as well. \\n• \\nAnalyzed the errors of the Deep Learning/AI model and designed strategies to overcome \\nthem. \\n• \\nKnowledge of Adding Deep learning/AI Model to production. \\n• \\nProficiency with deep learning framework such as tensorflow and keras. \\n• \\nProficiency with Python and basic libraries for machine learning such as scikit-learn and \\npandas. \\n• \\nProficiency with OpenCv and Pytorch. \\n• \\nProficiency with Deep learning algorithms and models such as CNN, RNN and Lstm. \\n• \\nGood understanding of linear algebra, machine learning, statistics and machine learning \\nprinciple(i.e. training, validation,etc…). \\n• \\nGood understanding of Word2vec,word embedding, bagofwords, information extraction,text \\nmining, stemming, Lemmetization and NER. \\n \\nCERTIFICATIONS \\n \\n• Tensorflow for AI-vision basics \\nCoursera | 12/20 – 12/20 \\nEDUCATION \\n \\nInformation technology/ B.TECH \\nKIIT University,BHUBANESHWAR \\n04/14 – 04/18 \\nCGPA-7.15 \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.strip()"
      ],
      "metadata": {
        "id": "RtOpW4W8Z0X7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(text.split())"
      ],
      "metadata": {
        "id": "5JEhN_5xZ--5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \"->>>>\",ent.label_)"
      ],
      "metadata": {
        "id": "Jxmc9Pt_aNwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NTEdZX4Xlv7T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}