{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1xgkrjTTDgMG74S-6yyW02H4Wdmi4I3Ya",
      "authorship_tag": "ABX9TyNkC0mzhgENGQGwbCaqMOvJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsk-003/Air-Quality/blob/main/final_23_jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmSYPKnTjLIc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIqyUHiq1s7W"
      },
      "outputs": [],
      "source": [
        "!pip install spacy-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy"
      ],
      "metadata": {
        "id": "UDF1xtyM13Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "xUoNYs1A2A0E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ImGJtPEn2iIx",
        "outputId": "f6c2e4b9-eae2-41f9-e0da-4f691b086473"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.7.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpxxjrA_2x06",
        "outputId": "e613c9df-2b9e-44ac-aca7-e7e467600afe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 23 09:46:59 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y716g5PktzeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "cv_data=json.load(open('/content/drive/MyDrive/23-01-24_model/manual.json','r'))"
      ],
      "metadata": {
        "id": "owibizjs4O0f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cv_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8tShwRI45Af",
        "outputId": "8da5c6e2-0095-4d28-f7fb-75573a50bf60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THVWVmOMt9IM",
        "outputId": "6e6e8d02-4e39-4fae-8aa9-d61a9305fa8f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sumit Singh EmailId sumit121singhgmailcom Contact 918375829395 skype Id  sumitsingh555 Skills  4 years experience product development  Experience Computer Vision NLP Machine Learning Deep Learning  Data Preparation Training model Model Evaluation Model Deployment  Image processing techniques using OpenCV  Experience Deep learning using Convolutional Neural Networks  CNN Recurrent Neural Network RNN BERT  Programming Language Python3  Frameworks Tensorflow keras PyTorch  Libraries OpenCV NLTK Sklearn  Experience perform operation GPU CPU  Algorithms CNN SVM Logistic Regression  Image Analysis Pattern Recognition  Show passion technologies cando attitude Experience Software Engineer Aug 2020 – March 2021 QuyTech Title – AI  ML Based Intelligent Video Advertisements Analysis Description implement tracking algorithms humans cars track car Human frame assign unique ID individual deep sort algorithm keep data memory old object detected frame algorithm assign old ID outcomes generated algorithm stored azure database data analysis business insights Technology – python3 OpenCV ImageProcessing Tensorflow Keras flask Title – Vmax Vision Description Build model detect Pupil image calculate PD Distance Technology – python3 OpenCV ImageProcessing Dlib Software Engineer Sept 2019 – June 2020 Skymet Weather Services Title  Palm Tree Count Description Oil palm trees important economic crops Malaysia tropical areas number oil palm trees plantation area important information predicting yield palm oil monitoring growing situation palm trees maximizing productivity etc Technology – OpenCV ImageProcessing Tensorflow Title – Text AutoTagging Description Able generate automatic tags documents Multiple Documents Support eg pptx docx txt xlsx csv process creating concise summary data computationally aim summarization include important relevant information text data Technology – NLPNLTK BAG Software Engineer Jul 2016 – Jul 2019 BlueApple Technologies Title – Face Recognition Description Working Face Recognition Loyalty train classifier dataset  Real Time Face Recognition System  Real Time Custom Objects Detection Tensorflow  Understanding business problems analyzing data using appropriate Statistical models generate insights Title – ChatBot Hospitality Reviews Program Description Chatbot technology improved rapidly past years gaining popularity across Hospitality Industry purpose chatbot mimic kind meaningful interactions customer might real employee usually text kind digital customer service agent responding queries providing useful information even answering specific questions  Data mining techniques education  Creating supporting data management workflow data collection storage analysis  Collecting Education base Data set clean manipulate data Education  Master Computer Application 76 marks Galgotias University 2016  Bachelor Computer Application 75 marks Swami Vivekanand Subharti University 2013',\n",
              " {'entities': [[0, 11, 'NAME'],\n",
              "   [95, 102, 'EXPERIENCE'],\n",
              "   [144, 618, 'SKILLS']]}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spacy_doc(file,data):\n",
        "  nlp = spacy.blank('en')\n",
        "  db = DocBin()\n",
        "\n",
        "  for text,annot in tqdm(data):\n",
        "    doc = nlp.make_doc(text)\n",
        "    annot = annot['entities']\n",
        "\n",
        "    ents = []\n",
        "    entity_indices = []\n",
        "\n",
        "    for start, end, label in annot:\n",
        "      skip_entity = False\n",
        "      for idx in range(start, end):\n",
        "        if idx in entity_indices:\n",
        "          skip_entity = True\n",
        "          break\n",
        "      if skip_entity==True:\n",
        "        continue\n",
        "\n",
        "      entity_indices = entity_indices + list(range(start, end))\n",
        "\n",
        "      try:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
        "\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      if span is None:\n",
        "        err_data = str([start, end]) + \"     \" + str(text)  + \"\\n\"\n",
        "        file.write(err_data)\n",
        "\n",
        "      else:\n",
        "        ents.append(span)\n",
        "\n",
        "    try:\n",
        "      doc.ents = ents\n",
        "      db.add(doc)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  return db"
      ],
      "metadata": {
        "id": "_0XcAOjEt-i4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "train,test = train_test_split(cv_data, test_size=0.2)"
      ],
      "metadata": {
        "id": "AKIZRVHQuGQw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train),len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN3IpmREuJAK",
        "outputId": "35523035-653e-46c5-ba0a-64a9e85c0741"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config /content/drive/MyDrive/23-01-24_model/base_config.cfg config.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-5ekMBnuLGp",
        "outputId": "5757d0e2-2e46-4fa5-9027-cfc66663660a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-23 09:49:29.892811: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-23 09:49:29.892870: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-23 09:49:29.894115: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-23 09:49:30.914290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('error.txt','w')\n",
        "\n",
        "db = get_spacy_doc(file,train)\n",
        "db.to_disk('train_data.spacy')\n",
        "\n",
        "\n",
        "db = get_spacy_doc(file,test)\n",
        "db.to_disk('test_data.spacy')\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYh6sF33uX-P",
        "outputId": "92b67117-82c4-450d-ddde-7c029543a118"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:00<00:00, 27.26it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 34.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(db.tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dtIJmBquj9p",
        "outputId": "dcea7962-fa1a-481a-b09d-3cbb5700e5b3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train /content/config.cfg --output ./output --paths.train ./train_data.spacy --paths.dev ./test_data.spacy --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11OElMXDuqOL",
        "outputId": "0f757b00-6cb1-4db7-c31d-14634f90b6ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-23 09:51:40.114609: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-23 09:51:40.114725: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-23 09:51:40.116300: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-23 09:51:41.671507: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "config.json: 100% 481/481 [00:00<00:00, 2.39MB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 3.37MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 3.47MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 4.15MB/s]\n",
            "model.safetensors: 100% 499M/499M [00:04<00:00, 107MB/s]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        3850.21    745.60    0.00    0.00    0.00    0.00\n",
            " 40     200      134055.50  33430.52    0.00    0.00    0.00    0.00\n",
            " 80     400         333.13  13091.42   14.29   12.50   16.67    0.14\n",
            "120     600           0.01  12510.69   16.67   16.67   16.67    0.17\n",
            "160     800           2.16  11937.64   16.67   16.67   16.67    0.17\n",
            "200    1000           0.00  11336.40   16.67   16.67   16.67    0.17\n",
            "240    1200         124.16  10720.04   20.00   25.00   16.67    0.20\n",
            "280    1400        1677.91  10199.19   20.00   25.00   16.67    0.20\n",
            "320    1600          17.51   9254.88   20.00   25.00   16.67    0.20\n",
            "360    1800           0.00   8364.92   16.67   16.67   16.67    0.17\n",
            "400    2000           0.00   7445.87   16.67   16.67   16.67    0.17\n",
            "440    2200           8.88   6426.71   16.67   16.67   16.67    0.17\n",
            "480    2400        7898.10   5441.50   18.18   20.00   16.67    0.18\n",
            "520    2600       10577.63   4610.80    0.00    0.00    0.00    0.00\n",
            "560    2800           2.62   3382.22    0.00    0.00    0.00    0.00\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model test"
      ],
      "metadata": {
        "id": "DUv9rtIN6QFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('/content/output/model-best')"
      ],
      "metadata": {
        "id": "sbOszsW7u3g9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp('my name is Ritika Jadhav I worked at IBM . my skillset is expert in python programming machine learning deep learning data analysis NLP generative ai expert in scikit learn library.')\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \"->>>>\",ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC2hEjVo6Vnw",
        "outputId": "67fdae61-c037-4f5c-9742-cad841563b34"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ritika Jadhav ->>>> NAME\n",
            "python programming machine learning deep learning data analysis NLP generative ai expert in scikit learn library. ->>>> SKILLS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g-uPjiYX6o8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsqI9QEvPTsF",
        "outputId": "26b1aacf-377d-48c5-9edd-0587c6db3af0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.17-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.9 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.17 PyMuPDFb-1.23.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, fitz"
      ],
      "metadata": {
        "id": "sNIvr47qYW6s"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = '/content/drive/MyDrive/23-01-24_model/Resume (1).pdf'"
      ],
      "metadata": {
        "id": "S1BsHznQYbcw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = fitz.open(fname)\n",
        "doc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T9CJL3UYjH7",
        "outputId": "e20a46f8-7743-4d28-afa7-1ca7859abfdf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document('/content/drive/MyDrive/23-01-24_model/Resume (1).pdf')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \"\n",
        "for page in doc:\n",
        "  text = text + str(page.get_text())"
      ],
      "metadata": {
        "id": "aFEzpwkCZGAf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(text.split())"
      ],
      "metadata": {
        "id": "5JEhN_5xZ--5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "zaddCw-EaB7b",
        "outputId": "3e29ec70-5aa7-493a-c01a-b2be5fd40624"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Naman Grover +91 8700710350 / ngrover.241@gmail.com / Delhi, India / LinkedIn Knowledgeable in various avenues of Machine Learning. Ability to develop suitable Product Codes and Algorithms. Proactive with a problem-solving attitude. Ability to build innovative AI solutions for real-life concerns. WORK EXPERIENCE Asmadiya Technologies - AI/ML Engineer Jan 2021 – April 2021 / Pune, India • Researched, prototyped, built features and optimized the state-of-the-art deep learning techniques like sequence to sequence, LSTMs and attention using scikit-learn, keras and tensorflow for english-french machine translation. • Applied various transfer-learning techniques using pre-trained word-embeddings like Glove, Bert, Universal Sentence Encoder for text similarity tasks. • Developed text mining pipelines to analyze large unstructured datasets with Latent Dirichlet Allocation (LDA), text classification and sentiment analysis. • Collaborated with colleagues and executed other duties as assigned by the managers. BlackNet - Machine Learning Engineer Dec 2019 – Nov 2020 / New Delhi, India • Applied Machine Learning and statistical modelling techniques to develop and evaluate algorithms to improve performance, quality, data management and accuracy. • Steered rapid model creation in python using pandas, numpy, scikit-learn and plotly for data visualization. • Created multivariate-regression based attribution models and segmentation models using k-means clustering. • Interpreted twitter data and analyzed results using statistical and data visualization techniques to provide insights about the impact of covid-19 on people in India. Udyatmat MA Viramavsa Pvt. Ltd. - Deep Learning Engineer Intern July 2019 – Aug 2019 / Delhi, India • Collected all assigned charts / data from scratch. • Performed object detection using single shot multi-box detector. • Applied image enhancement operations like contrast, sharpening, scaling and affine transformation to get the meaningful data from the image. • Implemented different CNN architectures like sequence of convolutions, pooling, activation functions to improve the accuracy. Geeksforgeeks – Technical Content Writing Intern May 2019 – Aug 2019 • Organized material to research and complete writing tasks. • Performed supervised research on technical content. • Researched and supported the development of technical manuals, publications, and logistics support documentation and logistics proposals. • Ensured technical verbiage is easy to understand. EDUCATION BACHELOR OF TECHNOLOGY IN COMPUTER SCIENCE Guru Gobind Singh Indraprastha University GPA – 8.3 2017 – 2021 / New Delhi, India SENIOR SECONDARY (PRE-ENGINEERING) St. Andrews Scots Sr. Sec. School Percentage – 92.6% 2015 – 2016 / Delhi, India SECONDARY St. Andrews Scots Sr. Sec. School CGPA – 9.4 2013 – 2014 / Delhi, India PROJECTS DETECTION OF CHILD PREDATORS AND CYBER HARASSERS ON SOCIAL MEDIA • Oversaw and laid out development of NLP models to combat Fake news, Hate speech, and Abuse. • Cleaned pre-existing data and trained deep learning model to detect abuse, traumatic and disturbing content in images and videos shared on social media. • Worked with multiple stakeholders to reduce the legal liabilities of models below the human level bias. AUTO CONTENT MODERATION FOR OTT PLATFORMS • Created an auto-content moderation system in order to generate family friendly tv shows and movies. • Developed integrated speech, text and vision systems which have the ability to suppress abusive sentences and blur out nude frames. • Used video classification model and CMU sphinx for Text to speech. SMART SEARCH USING ELASTICSEARCH • Utilized Elasticsearch in order to store and retrieve data that consists pre-existing set of Questions and Answers. • Applied Universal Sentence Encoder algorithm to generate semantically correct outputs. • Created a search as you type feature using Elasticsearch in order to generate the best results in very less time. SKILLS Programming Language: Python, C++; Tools and Frameworks: Pandas, Scikit-learn, Dash, Django, MySQL, Tensorflow, Tflite, Tensorboard, Huggingface; Data Science and Analytics: Numpy, Matplotlib, Seaborn, Pandas, Vaex, NLTK, Spacy ACHIEVEMENTS AND CERTIFICATIONS • Coding Blocks Classroom certification program in Machine Learning with python. • Coding Blocks Classroom certification program in Python for Developers course. • Google Explore ML Facilitator Certification. • Udemy Deep Learning-Learn with Tensor Flow and Python Certification. • Coursera certification in Natural Language Processing with Classification and Vector Spaces. • Secured 3rd position in HackGTBIT (2019). • Achieved rank 110 out of 35,000 in Analytics Vidhya sales prediction hackathon (2020). • Cleared Actuarial Common Entrance Test- 2019.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \"->>>>\",ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxmc9Pt_aNwJ",
        "outputId": "7ffbb174-cddb-40b8-fb2f-2b4400ee68e3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naman Grover ->>>> NAME\n",
            "SKILLS Programming Language: Python, C++; Tools and Frameworks: Pandas, Scikit-learn, Dash, Django, MySQL, Tensorflow, Tflite, Tensorboard, Huggingface; Data Science and Analytics: Numpy, Matplotlib, Seaborn, Pandas, Vaex, NLTK, ->>>> SKILLS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RsgGq8S_7Gcz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}